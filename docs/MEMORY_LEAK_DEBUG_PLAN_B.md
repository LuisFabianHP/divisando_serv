# ðŸ”§ Memory Leak Debug: Plan B (Aggressive Analysis)

## Status: âš ï¸ CRÃTICO - Fix no funcionÃ³ (93% heap despuÃ©s del deploy)

El fix de rate limiter + logger cleaning NO redujo el heap (aÃºn 93%).

## Posible causa raÃ­z:
1. **Railway NO reiniciÃ³** (aunque push se completÃ³)
2. **Fix INSUFICIENTE** - hay OTRO memory leak mayor no identificado  
3. **Queries sin paginar** acumulan resultados en memoria
4. **Variables globales** en closures retienen referencias

---

## Plan B: Debugging Profundo

### Paso 1: Forzar Restart en Railway
```bash
# En Railway Dashboard:
1. Services â†’ divisando-api
2. Settings â†’ Redeploy (Force)
3. Esperar 2-3 minutos
4. Ver logs para confirmar que los imports nuevos aparecen
```

### Paso 2: Verificar que Fix se aplicÃ³  
Buscar en logs exactamente ESTOS mensajes despuÃ©s de restart:
```
âœ… [Nuevo] "Cerrando rate limiter store..."
âœ… [Nuevo] "Cerrando loggers..."
```

Si NO aparecen â†’ El cÃ³digo NO se recargÃ³

### Paso 3: Buscar OTRO Memory Leak
Si aÃºn sigue en 93%, entonces hay un leak DIFERENTE. Posibilidades:

**A) Queries sin pagination:**
```javascript
// âŒ MAL: Devuelve TODOS los documentos a memoria
const allUsers = await User.find({});

// âœ… BIEN: Limitar resultados
const recentUsers = await User.find({}).limit(100).lean();
```

**B) Variables globales en closures:**
```javascript
// âŒ MAL: "results" queda en closure y nunca se libera
let results = null;
const saveResults = (data) => {
  results = data; // Retiene referencia
};

// âœ… BIEN: Limpiar explÃ­citamente  
let results = null;
const clearResults = () => {
  results = null; // Liberar memoria
};
```

**C) Axios response no siendo limpia:**
```javascript
// âŒ MAL: response.data queda en memoria
const response = await axios.get(url);
process.data = response.data; // Referencia global

// âœ… BIEN: Extraer solo lo necesario
const { data } = await axios.get(url);
const needed = { rate: data.rate }; // Solo copiar lo esencial
```

---

## Paso 4: Generar Heap Dump (Si aÃºn > 85%)

### TÃ©cnica 1: Usar Clinic.js
```bash
cd divisando_serv
npm install clinic
clinic doctor -- node server.js
# Luego hacer traffic durante 1 min
# Clinic generarÃ¡ reporte vs/html
```

### TÃ©cnica 2: Node Inspector
```bash
# En Railway, no se puede acceder directo, pero podemos:
node --inspect-brk server.js  # Con breakpoint
# Luego en Chrome: chrome://inspect

# O guardar heap dump a archivo:
node -e "require('v8').writeHeapSnapshot('heap.bin')"
```

### TÃ©cnica 3: Agregar logging de memoria agresivo
```javascript
// Agregar a server.js
const memInterval = setInterval(() => {
  const usage = process.memoryUsage();
  console.log(`[MEM] Heap: ${(usage.heapUsed/1024/1024).toFixed(1)}MB / ${(usage.heapTotal/1024/1024).toFixed(1)}MB (${((usage.heapUsed/usage.heapTotal)*100).toFixed(1)}%) | External: ${(usage.external/1024/1024).toFixed(1)}MB`);
}, 10000); // Cada 10 segundos

process.on('SIGTERM', () => {
  clearInterval(memInterval);
  // ... rest of shutdown
});
```

---

## Sospechosos Actuales (Prioridad):

### ðŸ”´ CRÃTICO:
1. **axios response caching** en fetchExchangeRates.js
   - Â¿Se estÃ¡ guardando response.data en variables globales?
   
2. **Queries sin `.lean()`** en authController.js
   - Au queries devuelven Mongoose documents completos
   - Son objetos pesados con mÃ©todos

3. **winston-logger buffers** en memoria

### ðŸŸ  ALTO:
4. **Rate limiter store** (aunque agregamos shutdown, puede no estar limpiÃ¡ndose)
5. **MongoDB connection pool** (maxPoolSize=10 por defecto)
6. **Event listeners** sin cleanup (aunque buscamos y no encontramos)

---

## Acciones Inmediatas:

### 1. FORZAR RESTART en Railway
- Gateway.js debe estar en versiÃ³n con imports nuevos
- Verificar que `apiRateLimiter.store` estÃ¡ exportado

### 2. SI SIGUE EN > 90%:
- Agregar logging de memoria cada 10 segundos
- Buscar picos o crecimientos lineales
- Identificar quÃ© estÃ¡ consumiendo

### 3. SI SIGUE EN > 85% DESPUÃ‰S DE 2h:
- Generar heap dump
- Analizar quÃ© objetos son mÃ¡s grandes
- Identificar leak raÃ­z

---

## Alternativas Nucleares (Si todo falla):

### OpciÃ³n 1: Limitar Node.js Heap mÃ¡s
```javascript
// En package.json start script:
"start": "node --expose-gc --max-old-space-size=256 server.js"
// Reduce de 384MB a 256MB - fuerza GC mÃ¡s agresivo
```

### OpciÃ³n 2: Implementar Periodic Restart
```javascript
// Cada 4 horas, reiniciar el servidor
const restartInterval = 4 * 60 * 60 * 1000;
setTimeout(() => {
  console.log('ðŸ“ Reinicio programado para evitar memory leak');
  process.exit(0); // Railway auto-restarts
}, restartInterval);
```

### OpciÃ³n 3: Cambiar a Render/Fly.io
- Railway free tier = 512MB heap total
- Render = 512MB tambiÃ©n
- Fly.io = 256MB pero mejor optimizado
- Mejor: Aumentar a plan pago

---

## Timelines:

- **Ahora:** Force restart en Railway (5 min)
- **+10 min:** Verificar logs,veir si heap bajÃ³
- **+20 min:** Si NO bajÃ³, agregar logging de memoria
- **+1h30:** Analizar logs, identificar pico/leak
- **+2h:** Si persiste, generar heap dump

---

**ACCIÃ“N RECOMENDADA AHORA:**
1. Force Restart en Railway Dashboard
2. Esperar 3 minutos
3. Verificar logs si aparecen menciones al nuevo cÃ³digo
4. Si heap sigue > 90%, reportar y proceder con Plan Debug Profundo
